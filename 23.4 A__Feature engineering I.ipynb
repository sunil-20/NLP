{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26b9043e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Sunil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\anaconda_2021\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda_2021\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda_2021\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda_2021\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda_2021\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda_2021\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import sklearn \n",
    "import spacy \n",
    "import re \n",
    "import nltk \n",
    "from  nltk.corpus import gutenberg \n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "nltk.download('gutenberg')\n",
    "\n",
    "!python -m spacy download en\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4ebf96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuation and numbers from the text\n",
    "\n",
    "def text_cleaner(text): \n",
    "    text = re.sub(r'--',' ', text)\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b', '', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bba07dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# dealing with the chapter indicators\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e039d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parsing the text with nlp module\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b630c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupping the parsed doc into sentences\n",
    "alice_sents = [[sent, 'Carroll']for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen']for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combining the sentences from two novel to one df\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns= ['text', 'author'])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d7cda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing stopwords and punctuation and lemmatize the token\n",
    "for i, sentence in enumerate(sentences['text']):\n",
    "    sentences.loc[i, 'text'] = ' '. join(\n",
    "    [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc7a170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer='word')\n",
    "X = vectorizer.fit_transform(sentences['text'])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[['text', 'author']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5e67a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abode</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abominate</th>\n",
       "      <th>...</th>\n",
       "      <th>younker</th>\n",
       "      <th>youth</th>\n",
       "      <th>youthful</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shall late</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4852 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  abbreviation  abdication  abide  ability  able  abode  \\\n",
       "0    0     0             0           0      0        0     0      0   \n",
       "1    0     0             0           0      0        0     0      0   \n",
       "2    0     0             0           0      0        0     0      0   \n",
       "3    0     0             0           0      0        0     0      0   \n",
       "4    0     0             0           0      0        0     0      0   \n",
       "\n",
       "   abominable  abominate  ...  younker  youth  youthful  zeal  zealand  \\\n",
       "0           0          0  ...        0      0         0     0        0   \n",
       "1           0          0  ...        0      0         0     0        0   \n",
       "2           0          0  ...        0      0         0     0        0   \n",
       "3           0          0  ...        0      0         0     0        0   \n",
       "4           0          0  ...        0      0         0     0        0   \n",
       "\n",
       "   zealous  zealously  zigzag  \\\n",
       "0        0          0       0   \n",
       "1        0          0       0   \n",
       "2        0          0       0   \n",
       "3        0          0       0   \n",
       "4        0          0       0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2     remarkable Alice think way hear Rabbit oh dear  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                         shall late  Carroll  \n",
       "\n",
       "[5 rows x 4852 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "468562d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building with hyperparameter tuning\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text', 'author'], 1))\n",
    "\n",
    "# splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.4, random_state= 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "92716a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'max_depth': [2, 3, 4, 5],\n",
       "                         'min_samples_split': [3, 5, 7, 9],\n",
       "                         'n_estimators': [3, 5, 10, 15]})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Models\n",
    "lr_params = {\"penalty\": [\"l1\", \"l2\"]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gbc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "clf_lr = GridSearchCV(lr, lr_params, cv=5)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_rfc = GridSearchCV(rfc, rfc_params, cv=5)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "\n",
    "clf_gbc = GridSearchCV(gbc, gbc_params, cv=5)\n",
    "clf_gbc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f91ce63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9456145866079849\n",
      "\n",
      "Test set score: 0.8939679547596607\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.7164413706381642\n",
      "\n",
      "Test set score: 0.7016965127238455\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8314995284501729\n",
      "\n",
      "Test set score: 0.827521206409048\n"
     ]
    }
   ],
   "source": [
    "#print scores\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', clf_lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', clf_rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', clf_gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "556ffa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1st</th>\n",
       "      <th>29th</th>\n",
       "      <th>29th september</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abbreviation living</th>\n",
       "      <th>abdication</th>\n",
       "      <th>abdication neighbour</th>\n",
       "      <th>abide</th>\n",
       "      <th>abide consequence</th>\n",
       "      <th>abide figure</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand australia</th>\n",
       "      <th>zealous</th>\n",
       "      <th>zealous officer</th>\n",
       "      <th>zealous subject</th>\n",
       "      <th>zealously</th>\n",
       "      <th>zealously discharge</th>\n",
       "      <th>zigzag</th>\n",
       "      <th>zigzag go</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shall late</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1st  29th  29th september  abbreviation  abbreviation living  abdication  \\\n",
       "0    0     0               0             0                    0           0   \n",
       "1    0     0               0             0                    0           0   \n",
       "2    0     0               0             0                    0           0   \n",
       "3    0     0               0             0                    0           0   \n",
       "4    0     0               0             0                    0           0   \n",
       "\n",
       "   abdication neighbour  abide  abide consequence  abide figure  ...  \\\n",
       "0                     0      0                  0             0  ...   \n",
       "1                     0      0                  0             0  ...   \n",
       "2                     0      0                  0             0  ...   \n",
       "3                     0      0                  0             0  ...   \n",
       "4                     0      0                  0             0  ...   \n",
       "\n",
       "   zealand australia  zealous  zealous officer  zealous subject  zealously  \\\n",
       "0                  0        0                0                0          0   \n",
       "1                  0        0                0                0          0   \n",
       "2                  0        0                0                0          0   \n",
       "3                  0        0                0                0          0   \n",
       "4                  0        0                0                0          0   \n",
       "\n",
       "   zealously discharge  zigzag  zigzag go  \\\n",
       "0                    0       0          0   \n",
       "1                    0       0          0   \n",
       "2                    0       0          0   \n",
       "3                    0       0          0   \n",
       "4                    0       0          0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2     remarkable Alice think way hear Rabbit oh dear  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                         shall late  Carroll  \n",
       "\n",
       "[5 rows x 35551 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using 1-gram and 2-gram as features\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "bow_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([bow_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99584711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9625903803835272\n",
      "\n",
      "Test set score: 0.8906691800188501\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.77648538195536\n",
      "\n",
      "Test set score: 0.7780395852968898\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8314995284501729\n",
      "\n",
      "Test set score: 0.827521206409048\n"
     ]
    }
   ],
   "source": [
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text', 'author'], 1))\n",
    "\n",
    "# splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size= 0.4, random_state= 123)\n",
    "\n",
    "# Models\n",
    "lr_params = {\"penalty\": [\"l1\", \"l2\"]}\n",
    "lr = LogisticRegression()\n",
    "\n",
    "rfc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "gbc_params = {\"n_estimators\": [3, 5, 10, 15],\n",
    "              \"max_depth\": [2, 3, 4, 5],\n",
    "              \"min_samples_split\": [3, 5, 7, 9]}\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "clf_lr = GridSearchCV(lr, lr_params, cv=5)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "clf_rfc = GridSearchCV(rfc, rfc_params, cv=5)\n",
    "clf_rfc.fit(X_train, y_train)\n",
    "\n",
    "clf_gbc = GridSearchCV(gbc, gbc_params, cv=5)\n",
    "clf_gbc.fit(X_train, y_train)\n",
    "\n",
    "#print scores\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print('Training set score:', clf_lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print('Training set score:', clf_rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print('Training set score:', clf_gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf_gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afbc12c",
   "metadata": {},
   "source": [
    "Here, Random Forest didn't perform good as compared to the model in the checkpoint. GBC did good in the 1-gram and 2-gram. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
