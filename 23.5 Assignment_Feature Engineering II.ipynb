{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e0507a",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5530b98",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\Sunil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.1.0/en_core_web_sm-3.1.0-py3-none-any.whl (13.6 MB)\n",
      "Requirement already satisfied: spacy<3.2.0,>=3.1.0 in c:\\anaconda_2021\\lib\\site-packages (from en-core-web-sm==3.1.0) (3.1.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.5)\n",
      "Requirement already satisfied: jinja2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.5)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (20.9)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.20.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.9 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (8.0.10)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.8.2)\n",
      "Requirement already satisfied: setuptools in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.59.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (0.7.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\anaconda_2021\\lib\\site-packages (from spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.25.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda_2021\\lib\\site-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\anaconda_2021\\lib\\site-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\anaconda_2021\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (3.7.4.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda_2021\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (2020.12.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\anaconda_2021\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\anaconda_2021\\lib\\site-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-sm==3.1.0) (1.1.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "!python -m spacy download en\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07f92bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the data, removing --\n",
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
    "    text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b', ' ', text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53abc830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(I, shall, be, late, !, ')</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                         (I, shall, be, late, !, ')  Carroll"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
    "alice = gutenberg.raw('carroll-alice.txt')\n",
    "\n",
    "# Dealing with the chapter indicator\n",
    "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "alice = re.sub(r'CHAPTER .*', '', alice)\n",
    "    \n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)\n",
    "\n",
    "# Parse the cleaned novels.\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)\n",
    "\n",
    "# Groupping the parsed doc into sentences\n",
    "alice_sents = [[sent, 'Carroll']for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, 'Austen']for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combining the sentences from two novel to one df\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns= ['text', 'author'])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d226b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords and punctuation and lemmatize the token\n",
    "for i, sentence in enumerate(sentences['text']):\n",
    "    sentences.loc[i, 'text'] = ' '. join(\n",
    "    [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1bc1c5",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e808cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abominate</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absurd</th>\n",
       "      <th>...</th>\n",
       "      <th>yer</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>young</th>\n",
       "      <th>youth</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>shall late</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2856 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abide  ability  able  abominate  abroad  absence  absent  absolute  \\\n",
       "0    0.0      0.0   0.0        0.0     0.0      0.0     0.0       0.0   \n",
       "1    0.0      0.0   0.0        0.0     0.0      0.0     0.0       0.0   \n",
       "2    0.0      0.0   0.0        0.0     0.0      0.0     0.0       0.0   \n",
       "3    0.0      0.0   0.0        0.0     0.0      0.0     0.0       0.0   \n",
       "4    0.0      0.0   0.0        0.0     0.0      0.0     0.0       0.0   \n",
       "\n",
       "   absolutely  absurd  ...  yer  yes  yesterday  yield  young  youth  zeal  \\\n",
       "0         0.0     0.0  ...  0.0  0.0        0.0    0.0    0.0    0.0   0.0   \n",
       "1         0.0     0.0  ...  0.0  0.0        0.0    0.0    0.0    0.0   0.0   \n",
       "2         0.0     0.0  ...  0.0  0.0        0.0    0.0    0.0    0.0   0.0   \n",
       "3         0.0     0.0  ...  0.0  0.0        0.0    0.0    0.0    0.0   0.0   \n",
       "4         0.0     0.0  ...  0.0  0.0        0.0    0.0    0.0    0.0   0.0   \n",
       "\n",
       "   zealous                                               text   author  \n",
       "0      0.0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1      0.0  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2      0.0     remarkable Alice think way hear Rabbit oh dear  Carroll  \n",
       "3      0.0                                            oh dear  Carroll  \n",
       "4      0.0                                         shall late  Carroll  \n",
       "\n",
       "[5 rows x 2856 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vectorizer = TfidfVectorizer(max_df = 0.5, min_df= 2, use_idf= True, norm = u'l2', smooth_idf= True)\n",
    "\n",
    "# applying the vectorizer\n",
    "X = vectorizer.fit_transform(sentences['text'])\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([tfidf_df, sentences[['text', 'author']]], axis = 1)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fd986f",
   "metadata": {},
   "source": [
    "## Modeling phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8e8899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.9163784973278843\n",
      "\n",
      "Test set score: 0.8864278982092366\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.981766740018862\n",
      "\n",
      "Test set score: 0.8873704052780396\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8588494184218799\n",
      "\n",
      "Test set score: 0.8539114043355325\n"
     ]
    }
   ],
   "source": [
    "# Predict the author in the sentences\n",
    "\n",
    "Y = sentences['author']\n",
    "X = np.array(sentences.drop(['text', 'author'], 1))\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.4, random_state = 44)\n",
    "\n",
    "#Model\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print('----------------------Logistic Regression Scores----------------------')\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "print('----------------------Random Forest Scores----------------------')\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "print('----------------------Gradient Boosting Scores----------------------')\n",
    "print('Training set score:', gbc.score(X_train, y_train))\n",
    "print('\\nTest set score:', gbc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd180b0",
   "metadata": {},
   "source": [
    "## Creating TF-IDF  Vectors for the last three sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced61ab",
   "metadata": {},
   "source": [
    "Consider the following sentences:\n",
    "\n",
    "1. \"The best Monty Python sketch is the one about the dead parrot; I laughed so hard.\"\n",
    "2. \"I laugh when I think about Python's Ministry of Silly Walks sketch; it is funny, funny, funny, the best!\"\n",
    "3. \"Chocolate is the best ice cream dessert topping, with a great taste.\"\n",
    "4. \"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing.\"\n",
    "5. \"I would rather put strawberries on my ice cream for dessert; they have the best taste.\"\n",
    "6. \"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71fa1270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Last three sentences in the vectorizer\n",
    "sentA = \"The Lumberjack Song is the funniest Monty Python bit; I can't think of it without laughing.\"\n",
    "sentB = \"I would rather put strawberries on my ice cream for dessert; they have the best taste.\"\n",
    "sentC = \"The taste of caramel is a fantastic accompaniment to tasty mint ice cream.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e85bdb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform([sentA, sentB, sentC])\n",
    "features = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "denselist = dense.tolist()\n",
    "sent_df = pd.DataFrame(denselist, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b2e313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accompaniment</th>\n",
       "      <th>best</th>\n",
       "      <th>bit</th>\n",
       "      <th>can</th>\n",
       "      <th>caramel</th>\n",
       "      <th>cream</th>\n",
       "      <th>dessert</th>\n",
       "      <th>fantastic</th>\n",
       "      <th>for</th>\n",
       "      <th>funniest</th>\n",
       "      <th>...</th>\n",
       "      <th>song</th>\n",
       "      <th>strawberries</th>\n",
       "      <th>taste</th>\n",
       "      <th>tasty</th>\n",
       "      <th>the</th>\n",
       "      <th>they</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>without</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.320872</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.271642</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210254</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.210254</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163281</td>\n",
       "      <td>0.276458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.276458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250183</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.194290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.328961</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accompaniment      best       bit       can   caramel     cream   dessert  \\\n",
       "0       0.000000  0.000000  0.271642  0.271642  0.000000  0.000000  0.000000   \n",
       "1       0.000000  0.276458  0.000000  0.000000  0.000000  0.210254  0.276458   \n",
       "2       0.328961  0.000000  0.000000  0.000000  0.328961  0.250183  0.000000   \n",
       "\n",
       "   fantastic       for  funniest  ...      song  strawberries     taste  \\\n",
       "0   0.000000  0.000000  0.271642  ...  0.271642      0.000000  0.000000   \n",
       "1   0.000000  0.276458  0.000000  ...  0.000000      0.276458  0.210254   \n",
       "2   0.328961  0.000000  0.000000  ...  0.000000      0.000000  0.250183   \n",
       "\n",
       "      tasty       the      they     think        to   without     would  \n",
       "0  0.000000  0.320872  0.000000  0.271642  0.000000  0.271642  0.000000  \n",
       "1  0.000000  0.163281  0.276458  0.000000  0.000000  0.000000  0.276458  \n",
       "2  0.328961  0.194290  0.000000  0.000000  0.328961  0.000000  0.000000  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
